Python (11) - sortowanie

PLAN

    Podstawy sortowania
    Sortowanie w Pythonie
    Sortowanie kilku liczb
    Proste metody sortowania
    Sortowanie przez wybór (selectsort)
    Sortowanie przez wstawianie (insertsort)
    Sortowanie przez zamianę (bubblesort)
    Sortowanie przez wstrząsanie (shakersort)
    Sortowanie Shella (shellsort)
    Sortowanie szybkie (quicksort)
    Sortowanie przez scalanie (mergesort)
    

Podstawy sortowania
WPROWADZENIE

Sortowaniem nazywamy proces ustawiania zbioru obiektów w określonym porządku [Wirth]. Sortowanie stosuje się w celu ułatwienia późniejszego wyszukiwania elementów sortowanego zbioru.

SPECYFIKACJA
Problem sortowania [Cormen].

DANE WEJŚCIOWE
Ciąg N liczb (a_1, a_2, ..., a_N).

DANE WYJŚCIOWE
Permutacja (zmiana kolejności) (a_1', a_2', ..., a_N')
ciągu wejściowego taka, że a_1' <= a_2' <= ... <= a_N'.

Podział metod sortowania:

    Sortowanie tablic (sortowanie wewnętrzne). Dane są przechowywane w szybkiej, ale ograniczonej pamięci o dostępie swobodnym. Znamy liczbę elementów. Sortowanie powinno być wykonane in situ (w miejscu, in place).
    Sortowanie plików sekwencyjnych (sortowanie zewnętrzne). Dane są przechowywane w powolnej, ale pojemnej pamięci zewnętrznej o dostępie sekwencyjnym. Nie znamy liczby przetwarzanych elementów, ale na końcu ciągu umieszczamy wyróżniony element, wartownika, który nie należy do tego zbioru. Czasem wartownik pełni rolę ogólniejszą niż tylko zakończenie zbioru. 

Algorytmy sortowania są zazwyczaj klasyfikowane według kilku kryteriów.

    Złożoność czasowa (pesymistyczna, oczekiwana) - zależność liczby wykonanych operacji w stosunku do liczebności sortowanego zbioru (n).
    Złożoność pamięciowa.
    Sortowanie stabilne albo niestabilne.
    Sortowanie adaptacyjne (polega na wykonywaniu różnych sekwencji operacji dla różnych układów danych) albo nieadaptacyjne (sekwencja wykonywanych operacji nie zależy od kolejności danych). 

MODELE SORTOWANIA

Podstawowy model sortowania polega na porównywaniu całych kluczy w celu ustalenia, który jest większy. Mamy teoretyczne ograniczenie na złożoność czasową O(n*log(n)). Czasem można zastosować inne podejście.

W sortowaniu pozycyjnym na raz przetwarza się fragmenty kluczy, a nie całe klucze [radix sort]. Przykładem może być sprawdzanie kolejnych cyfr liczby naturalnej lub znaków w napisie. Można zaczynać sortowanie od cyfr najbardziej znaczących lub najmniej znaczących.

Jeżeli klucze należą do skończonego zbioru k-elementowego, to zamiast porównywania kluczy można zliczać wystąpienia kolejnych kluczy [counting sort]. Złożoność czasowa to O(n+k), złożoność pamięciowa to O(k) [klucze nierozróżnialne] lub O(n+k) [klucze rozróżnialne, to jest właściwie sortowanie bukietowe, bucket sort].
STABILNOŚĆ

Metodę sortowania nazywamy stabilną, jeżeli podczas procesu sortowania pozostaje nie zmieniony względny porządek obiektów o identycznych kluczach. Przykład: alfabetyczna lista nazwisk uczniów sortowana wg ocen.

Przykład sortowania par liczb całkowitych względem
pierwszej wartości.

(4, 1) (3, 7) (3, 1) (5, 6) - oryginalna kolejność
(3, 7) (3, 1) (4, 1) (5, 6) - kolejność zachowana
(3, 1) (3, 7) (4, 1) (5, 6) - kolejność zmieniona

PRZYKŁADOWE ALGORYTMY STABILNE

N to liczba elementów do posortowania, k to liczba różnych elementów.

    Sortowanie bąbelkowe (ang. bubblesort) - czas O(n^2), dodatkowa pamięć O(1).
    Sortowanie przez wstawianie (ang. insertion sort) - czas O(n^2), dodatkowa pamięć O(1).
    Sortowanie przez scalanie (ang. merge sort) - czas O(n*log(n)), wymaga O(n) dodatkowej pamięci.
    Sortowanie przez zliczanie (ang. counting sort lub count sort) - czas O(n + k), wymaga O(n + k) dodatkowej pamięci.
    Sortowanie kubełkowe (ang. bucket sort) - czas O(n), wymaga O(k) dodatkowej pamięci.
    Sortowanie pozycyjne (ang. radix sort) - czas O(d*(n+k)), gdzie k to wielkość domeny cyfr, a d szerokość kluczy w cyfrach. Wymaga O(n+k) dodatkowej pamięci.
    Sortowanie biblioteczne (ang. library sort) - czas O(n*log(n)), pesymistyczny O(n^2).
    Sortowanie algorytmem timsort stosowanym w Pythonie. 

PRZYKŁADOWE ALGORYTMY NIESTABILNE

    Sortowanie przez wybieranie (ang. selection sort) - czas O(n^2), może być stabilne po odpowiednich zmianach.
    Sortowanie Shella (ang. shellsort) - złożoność nieznana.
    Sortowanie grzebieniowe (ang. combsort) - złożoność nieznana.
    Sortowanie szybkie (ang. quicksort) - czas O(n*log(n)), pesymistyczny O(n^2), z wykorzystaniem algorytmu selekcji "mediana median" ("magicznych piątek") do wyszukiwania mediany, optymistyczna złożoność to O(n*log(n)).
    Sortowanie introspektywne (ang. introspective sort lub introsort) - czas O(n*log(n)).
    Sortowanie przez kopcowanie (ang. heapsort) - czas O(n*log(n)). 



Sortowanie w Pythonie
WPROWADZENIE

Opis sortowania w Pythonie można znaleźć w Sorting HOWTO w dokumentacji Pythona.

Python posiada wbudowaną funkcję sorted(), która z obiektu iterowalnego tworzy nową listę posortowaną.

Listy mają wbudowaną metodę do stabilnego sortowania elementów IN PLACE. Stosowany algorytm nosi nazwę timsort, a stworzył go Tim Peters w roku 2002 [Wikipedia]. Jest to algorytm hybrydowy, bazujący na merge sort i insertion sort. Jest też nazywany algorytmem adaptacyjnym. Algorytm timsort jest standardowym algorytmem sortowania w Pythonie od wersji 2.3. Stosowany jest także do sortowania macierzy w Java SE 7 i na platformie Android.

# Jeżeli L to lista, to mamy wywołanie postaci
# L.sort(cmp=None, key=None, reverse=False)

L.sort()            # sortowanie listy napisów (duże litery najpierw)

# Potrzebujemy case-insensitive sort.
# Stary sposób - określamy funkcję porównującą dwa obiekty.

L.sort(cmp=lambda x, y: cmp(x.lower(), y.lower()))

# Nowy sposób (Python 2.4) - podajemy klucz, czyli jakby sposób 
# patrzenia na obiekt. Nazwa "str" występuje jako nazwa klasy.
# Sortowanie jest stabilne.

L.sort(key=str.lower)

# Sortowanie pod względem długości napisów.

L.sort(key=len)

W bardziej złożonych sytuacjach można korzystać ze schematu DSU (Decorate, Sort, Undecorate) [Receptury].
ŁĄCZENIE SEKWENCJI POSORTOWANYCH

Istnieje ładne rozwiązanie w Recepturach (19.14, s. 737). Metoda sort() potrafi skorzystać z faktu, że podsekwencje są posortowane. Z drugiej strony, ta metoda działa ogólnie nawet dla nieposortowanych podsekwencji.

# Sortowanie przy założeniu, że sekwencje mieszczą się w pamięci.
def smallmerge(*subsequences):
    result = []
    for seq in subsequences:
        result.extend(seq)
    result.sort()
    return result

Jeżeli sekwencje są duże (nie mieszczą się w pamięci), to proponowane rozwiązanie korzysta z generatorów i sterty.
SORTOWANIE OBIEKTÓW WG ATRYBUTÓW

from operator import attrgetter

class Person:

    def __init__(self, name, money=0):
        self.name = name
        self.money = money

    def __repr__(self):
        return "Person({0!r}, {1})".format(self.name, self.money)

persons = []
persons.append(Person("Adam", 50))
persons.append(Person("Edek", 10))
persons.append(Person("Lolek", 20))
persons.append(Person("Bolek", 10))

# Sortowanie wg nazwiska.
persons.sort(key=lambda x: getattr(x, "name"))
persons.sort(key=attrgetter("name"))
# [Person('Adam', 50), Person('Bolek', 10), Person('Edek', 10), Person('Lolek', 20)]

# Sortowanie wg zarobków.
persons.sort(key=lambda x: getattr(x, "money"))
persons.sort(key=attrgetter("money"))
# [Person('Edek', 10), Person('Bolek', 10), Person('Lolek', 20), Person('Adam', 50)]

# Sortowanie wg zarobków, potem nazwiska.
persons.sort(key=lambda x: (getattr(x, "money"), getattr(x, "name")))
persons.sort(key=attrgetter("money", "name"))
# Zwraca krotkę (person.money, person.name).
# [Person('Bolek', 10), Person('Edek', 10), Person('Lolek', 20), Person('Adam', 50)]



Sortowanie kilku liczb
WPROWADZENIE

Dla N liczb możemy wykonać N*(N-1)/2 porównań między nimi. Jednak nie wszystkie porównania są niezbędne, aby posortować te liczby. Dla kilku przypadków sprawdzimy, ile maksymalnie porównań jest niezbędnych, a ile otrzymamy z podanego wzoru.

    Sortowanie dwóch liczb - niezbędne jedno porównanie
    Sortowanie trzech liczb - niezbędne 3 porównania (3*2/2=3)
    Sortowanie czterech liczb - niezbędne 5 porównań (4*3/2=6)
    Sortowanie pięciu liczb - niezbędne 7 porównań (5*4/2=10) 

N - liczba elementów do posortowania
N! - liczba możliwych permutacji N elementów
k - liczba bitów (zero lub jeden)
2**k - liczba możliwych ciągów k-elementowych zer i jedynek

k     2**k     N!     N
0        1      1     1
1        2      2     2
2        4
3        8      6     3
4       16
5       32     24     4
6       64
7      128    120     5

Dla większej liczby N nie jest łatwo podać dokładną liczbę porównań. Okazuje się, że dla dużego N dobre algorytmy sortowania wymagają liczby porównań proporcjonalnej do N*log(N). Zajmiemy się analizą sortowania kilku liczb.

Przy analizie wydajności algorytmów sortowania bierzemy pod uwagę liczbę instrukcji porównania i podstawienia, a także ilość pamięci potrzebnej do wykonania algorytmu.

SPECYFIKACJA
Problem: Sortowanie kilku liczb.

WEJŚCIE
Ciąg N liczb.

WYJŚCIE
Uporządkowany ciąg tych liczb od najmniejszej do największej.

SORTOWANIE 3 LICZB

Rozważmy problem posortowania trzech liczb (a, b, c). Łatwo możemy stworzyć drzewo algorytmu.

[ sort3 ]

W programie komputerowym dane są zwykle przechowywane w tablicy i zajmują pewną ilość pamięci. Przy sortowaniu dane przemieszczamy, ale nie do nowej lokalizacji, lecz w obrębie tablicy, przy wykorzystaniu ewentualnie jednego dodatkowego miejsca. Częstą operacją jest zamiana danych miejscami, przy wykorzystaniu tymczasowej lokalizacji. To zadanie wykonuje funkcja swap (trzy instrukcje podstawienia). Dane są przechowywane na liście.

def swap(L, left, right):
    """Zamiana miejscami dwóch elementów na liście."""
    # L[left], L[right] = L[right], L[left]
    item = L[left]
    L[left] = L[right]
    L[right] = item

Korzystając z drzewa algorytmu możemy napisać funkcję sort3(), która posortuję listę trzech liczb. Wykonamy maksymalnie trzy porównania i cztery podstawienia. Ilość instrukcji podstawienia jest minimalna.

def sort3(L):
    """Sortowanie listy trzech liczb w miejscu."""
    if L[0] <= L[1]:     # kolejność L[0], L[1]
        if L[2] <= L[0]:    # L[2], L[0], L[1]
            item = L[2]
            L[2] = L[1]
            L[1] = L[0]
            L[0] = item
        else:
            if L[1] <= L[2]:
                pass   # L[0], L[1], L[2]
            else:
                swap(L, 1, 2)   # L[0], L[2], L[1]
    else:                      # kolejność L[1], L[0]
        if L[2] <= L[1]:
            swap(L, 0, 2)   # L[2], L[1], L[0]
        else:
            if L[2] <= L[0]:   # L[1], L[2], L[0]
                item = L[0]
                L[0] = L[1]
                L[1] = L[2]
                L[2] = item
            else:
                swap(L, 0, 1)   # L[1], L[0], L[2]

Jeżeli zwiększymy liczbę postawień do dziewięciu, to możemy zapisać funkcję sort3() w bardziej zwartej postaci. Sortowanie jest stabilne.

def sort3(L):
    """Sortowanie listy trzech liczb w miejscu - tylko swap."""
    if L[0] > L[1]:
        swap(L, 0, 1)
    if L[1] > L[2]:
        swap(L, 1, 2)
    if L[0] > L[1]:
        swap(L, 0, 1)

SORTOWANIE 4 LICZB

Na bazie sortowania trzech liczb możemy stworzyć drzewo algorytmu sortowania czterech liczb. Liczba porównań nie będzie przekraczać 5. Napiszemy funkcję sortującą listę czterech liczb w miejscu, korzystając z sekwencji kilku przestawień dwóch elementów. Wykonamy dokładnie 5 porównań oraz najwyżej 15 podstawień (liczba podstawień nie jest optymalna). Sortowanie nie jest stabilne.

def sort4(L):
    """Sortowanie listy czterech liczb w miejscu - tylko swap."""
    if L[0] > L[1]:
        swap(L, 0, 1)
    if L[2] > L[3]:
        swap(L, 2, 3)
    # Porównanie większych elementów.
    if L[1] > L[3]:
        swap(L, 1, 3)
    # Porównanie mniejszych elementów.
    if L[0] > L[2]:
        swap(L, 0, 2)
    # Mamy min i max, porównujemy środkowe.
    if L[1] > L[2]:
        swap(L, 1, 2)

SORTOWANIE 5 LICZB

Optymalne sortowanie pięciu liczb nie jest proste, a drzewo algorytmu nie jest prostym powiększeniem drzewa sortowania czterech liczb. Napiszemy funkcję sortującą listę pięciu liczb w miejscu, korzystając z sekwencji kilku przestawień dwóch elementów. Wykonamy maksymalnie 7 porównań. Algorytm sortowania pięciu liczb zaproponował H. B. Demuth w swojej pracy doktorskiej z 1956 roku.

def sort5(L):
    """Sortowanie listy pięciu liczb w miejscu - używamy swap()."""
    # Krok 1.
    if L[0] > L[1]:
        swap(L, 0, 1)
    if L[3] > L[4]:
        swap(L, 3, 4)
    # Krok 2.
    if L[1] > L[4]:
        swap(L, 1, 4)
        swap(L, 0, 3)
    # Mamy [a, b, e, c, d].
    # Krok 3, wstawiamy e, które siedzi na L[2].
    if L[2] < L[1]:
        if L[2] < L[0]:
            swap(L, 2, 1)
            swap(L, 1, 0)   # mamy [e, a, b, c, d]
        else:
            swap(L, 1, 2)   # mamy [a, e, b, c, d]
    else:
        if L[2] > L[4]:
            swap(L, 2, 4)   # mamy [a, b, d, c, e], c jest za d!
    # Krok 4, umieszczamy c, które jest na razie na L[3].
    if L[3] < L[1]:
        if L[3] < L[0]:
            swap(L, 3, 2)
            swap(L, 2, 1)
            swap(L, 1, 0)
        else:
            swap(L, 3, 2)
            swap(L, 2, 1)
    else:
        if L[3] < L[2]:
            swap(L, 2, 3)



Proste metody sortowania
WPROWADZENIE

Dobrą miarą efektywności algorytmu sortowania jest liczba koniecznych porównań kluczy i liczba koniecznych przesunięć (przestawień) obiektów. Metody proste wymagają rzędu N**2 porównań, a metody zaawansowane rzędu N*log(N). Metody proste sortowania w miejscu:

    sortowanie przez wybór (selekcję),
    sortowanie przez wstawianie (umieszczanie),
    sortowanie przez zamianę (bąbelkowe). 

Metody proste sortowania wybiera się w następujących sytuacjach:

    jeżeli program sortowania musi być uruchomiony niewielką liczbę razy,
    jeżeli liczba elementów przeznaczonych do sortowania nie jest duża (powiedzmy, mniej niż tysiąc),
    jeżeli mamy do czynienia ze specyficznymi zbiorami danych (dane prawie posortowane, zbiory z dużą liczbą duplikatów). 

IMPLEMENTACJA

Przedstawione implementacje algorytmów sortowania będą maiały postać funkcji typu anysort(L, left, right), gdzie sortowane będą elemeny na liście L na pozycjach od left do right włącznie. Wykorzystywana jest pomocnicza funkcja swap(L, left, right), która zamienia miejscami elementy na pozycjach left i right.

def swap(L, left, right):
    """Zamiana miejscami dwóch elementów."""
    # L[left], L[right] = L[right], L[left]
    item = L[left]
    L[left] = L[right]
    L[right] = item

# Sedgewick korzysta z jeszcze jednej funkcji pomocniczej.

def compswap(L, left, right):
    """Zamiana miejscami dwóch elementów, jeżeli warunek jest spełniony."""
    if L[left] > L[right]:
        # L[left], L[right] = L[right], L[left]
        item = L[left]
        L[left] = L[right]
        L[right] = item

def anysort(L, left, right):
    """Sortowanie listy L w miejscu od left do right włącznie."""
    pass



Sortowanie przez wybór (selectsort)
WPROWADZENIE

Sortowanie przez wybór działa na zasadzie ciągłego wybierania najmniejszego elementu z coraz mniejszego zbioru danych. Algorytm jest niestabilny [b1,b2,a,c]. Wada algorytmu: czas jego działania prawie nie zależy od stopnia uporządkowania ciągu.

Porównania: (n-1) + (n-2) + ... + 2 + 1 = n*(n-1)/2.

Przestawienia: (n-1) [bardzo mało].

def selectsort(L, left, right):
    for i in range(left, right):
        k = i
        for j in range(i+1, right+1):
            if L[j] < L[k]:
                k = j
        swap(L, i, k)

WERSJA STABILNA

Zwiększając liczbę przestawień możemy otrzymać stabilną wersję sortowania przez wybór.

def selectsort(L, left, right):
    for i in range(left, right):
        k = i
        for j in range(i+1, right+1):
            if L[j] < L[k]:
                k = j
        item = L[k]
        while k > i:
            L[k] = L[k-1]
            k = k-1
        L[i] = item

WERSJA REKURENCYJNA

Sortowanie przez wybór ma strukturę rekurencyjną: ustaw najmniejszy element na pozycji left, sortuj L w zakresie od left+1 do right.

def selectsort(L, left, right):
    if left < right:
        k = left
        for j in range(left+1, right+1):
            if L[j] < L[k]:
                k = j
        item = L[k]
        while k > left:
            L[k] = L[k-1]
            k = k-1
        L[left] = item
        selectsort(L, left+1, right)



Sortowanie przez wstawianie (insertsort)
WPROWADZENIE

Sortowanie przez wstawianie polega na wstawianiu nowych elementów we właściwe miejsce już uporządkowanego zbioru. Algorytm jest stabilny. W czasie pracy algorytmu lewa strona tablicy zawiera rosnącą część posortowaną, a prawa strona tablicy zawiera malejącą część nieposortowaną, z której pobieramy kolejne elementy.

# Wersja nieadaptacyjna z dwiema pętlami for.

def insertsort(L, left, right):
    for i in range(left+1, right+1):
        for j in range(i, left, -1):   # od prawej do lewej (bez left)
            if L[j-1] > L[j]:
                swap(L, j-1, j)   # zamiana sąsiadów

# Wersja nieadaptacyjna z pętlami for i while.

def insertsort(L, left, right):
    for i in range(left+1, right+1):
        j = i
        while j > left:
            if L[j-1] > L[j]:
                swap(L, j-1, j)
            j = j-1

Porównania: 1 + 2 + ... + (n-1) = n*(n-1)/2.

Przestawienia: 1 + 2 + ... + (n-1) = n*(n-1)/2.
ULEPSZENIA

Można dokonać wielu ulepszeń:

    Można przestać porównywać elementy, gdy natrafimy na liczbę mniejszą od sprawdzanej, ponieważ z lewej strony liczby są już posortowane.
    Zamiast warunku j > left (w drugiej pętli) można znaleźć najmniejszy element i ustawić go na początku tablicy (wartownik).
    Można poprawić przestawianie sąsiednich elementów [przesuwanie zamiast kolejnych swap()]. 

# Wersja z wartownikiem wg Sedgewicka.
# Ta wersja jest adaptacyjna.

def insertsort(L, left, right):
    for i in range(right, left, -1):   # ustawiam wartownika
        if L[i-1] > L[i]: 
            swap(L, i-1, i)
    for i in range(left+2, right+1):
        j = i
        item = L[i]
        while item < L[j-1]:   # robimy miejsce na item
            L[j] = L[j-1]
            j = j-1
        L[j] = item

# https://pl.wikibooks.org/wiki/Kody_%C5%BAr%C3%B3d%C5%82owe/Sortowanie_przez_wstawianie
# Poprawiony kod pythonowy. Nie ma swap() i wartownika.

def insertsort(L, left, right):
    for i in range(left+1, right+1):   # L[left] jest posortowany
        item = L[i]
        j = i
        while j > left and L[j-1] > item:
            L[j] = L[j-1]   # robimy miejsce na item
            j = j-1
        L[j] = item

WERSJA REKURENCYJNA

Sortowanie przez wstawianie używa podejścia inkrementacyjnego: sortuj L w zakresie od left do j-1, potem wstaw L[j] we właściwe miejsce, aby otrzymać L posortowane w zakresie od left do j.

# Wersja rekurencyjna.

def insertsort(L, left, right):
    if left < right:
        insertsort(L, left, right-1)
        item = L[right]
        j = right
        # Tu widać, że wartownik upraszcza warunek pętli.
        while j > left and item < L[j-1]:   # robimy miejsce na item
            L[j] = L[j-1]
            j = j-1
        L[j] = item



Sortowanie prze zamianę (bubblesort)
WPROWADZENIE

W sortowaniu bąbelkowym największe liczby wypływają na koniec ciągu. Algorytm jest stabilny.

def bubblesort(L, left, right):
    for i in range(left, right):
        for j in range(left, right):
            if L[j] > L[j+1]:
                swap(L, j+1, j)

Porównania: (n-1)*(n-1).

Przestawienia: (n-1) + ... + 1 = n*(n-1)/2.

Ulepszenia:

    Pętla po j może kończyć się wcześniej, ponieważ posortowana prawa strona ciągu powiększa się.
    Można przerwać przetwarzanie, jeżeli przy kolejnym przejściu pętli nie nastąpiło przestawienie. 

# Wersja ulepszona wg Sysły.
def bubblesort(L, left, right):
    limit = right
    while True:
        k = left-1   # lewy wskaźnik przestawianej pary
        for i in range(left, limit):
            if L[i] > L[i+1]:
                swap(L, i, i+1)
                k = i
        if k > left:
            limit = k
        else:
            break

SORTOWANIE OBIEKTÓW WG RÓŻNYCH KRYTERIÓW

Podane wyżej funkcje pozwalają sortować listy różnych obiektów, które można ze sobą porównywać. Ale czasem chcemy zmienić sposób sortowania (np. malejąco) lub sortujemy obiekty, które można porównywać na wiele sposobów (np. rekordy w bazie danych). W tej sytuacji należy jako parametr funkcji sortujących podać funkcję porównującą obiekty. Przykład na bazie sortowania bąbelkowego:

def bubblesort(L, left, right, cmpfunc=cmp):
    for i in range(left, right):
        for j in range(left, right-i):
            if cmpfunc(L[j], L[j+1]) > 0:
                swap(L, j+1, j)

Zastosowanie funkcji.

import random

N = 100
alist = range(N)
random.shuffle(alist)

# Zwykłe sortowanie.
bubblesort(alist, 0, N-1)

# Sortowanie w odwrotnej kolejności.
bubblesort(alist, 0, N-1, cmpfunc=lambda x, y: -cmp(x, y))

Korzystamy tutaj z wyrażenia lambda i standardowej funkcji porównującej cmp(x, y), która zwraca jedną z trzech wartości [-1, 0, 1], jeżeli odpowiednio x < y, x równe y, x > y.

W Pythonie 3 nie ma wbudowanej funkcji cmp(x, y), ale można zdefiniować jej odpowiednik.

# What’s New In Python 3.0
# https://docs.python.org/3.0/whatsnew/3.0.html
cmp = lambda x, y: (x > y) - (x < y)



Sortowanie przez wstrząsanie (shakersort)
WPROWADZENIE

W sortowaniu przez wstrząsanie (inaczej: algorytm koktajlowy) przechodzimy przez dane na przemian: raz z lewa na prawo, raz z prawa na lewo. Jest to ulepszony algorytm sortowania bąbelkowego.

# Wersja na podstawie Wróblewskiego.
def shakersort(L, left, right):
    k = right
    while left < right:
        for j in range(right, left, -1):   # od prawej
            if L[j-1] > L[j]:
                swap(L, j-1, j)
                k = j
        left = k
        for j in range(left, right):   # od lewej
            if L[j] > L[j+1]:
                swap(L, j, j+1)
                k = j
        right = k


Sortowanie Shella (shellsort)
WPROWADZENIE

Jest to poprawione sortowanie przez wstawianie, sortowanie za pomocą malejących przyrostów. Na szybkość algorytmu wpływa wybór sekwencji przyrostów. Przykładowe sekwencje, które dają dobrą wydajność:

    1, 4, 13, 40, 121, 364, 1093, 3280, ...
    a[1] = 1, a[n + 1] = 3 * a[n] + 1, czyli a[n] = (3 ** n - 1) / 2;
    1, 8, 23, 77, 281, 1073, 4193, ...
    a[1] = 1, a[2] = 8, a[n] = 1 + 3 * 2 ** (n-2) + 4 ** (n - 1) dla n > 2. 

# Wersja wg Kernighana i Ritchiego.
# Oryginalna sekwencja przyrostów Shella: 1, 2, 4, 8, 16, 32, ...
# Metoda degeneruje się do czasu kwadratowego dla złośliwych danych.

def shellsort(L, left, right):
    h = (right - left) // 2
    while h > 0:
        for i in range(left + h, right + 1):
            for j in range(i, left + h - 1, -h):
                if L[j - h] > L[j]:
                    swap(L, j - h, j)
        h = h // 2

# Wersja wg Sedgewicka.

def shellsort(L, left, right):
    # Ustalenie największego kroku z sekwencji:
    # 1, 4, 13, 40, 121, 364, 1093, 3280, 9841, ...
    h = 1
    while h <= (right-left) // 9:
        h = 3*h+1
    while h > 0:
        for i in range(left+h, right+1):
            j = i
            # Zamiast swap() mamy przesuniecia.
            item = L[i]
            while j >= left+h and item < L[j-h]:
                L[j] = L[j-h]
                j = j-h
            L[j] = item
        h = h // 3



Sortowanie szybkie (quicksort)
WPROWADZENIE

Sortowanie szybkie to poprawiony algorytm sortowania bąbelkowego. Podstawowa wersja algorytmu została wynaleziona w 1960 roku przez Hoare'a i od tego czasu był intensywnie badany. Stosowana jest zasada dziel i zwyciężaj. Algorytm jest klasy O(N*log(N)) w typowych sytuacjach, oraz O(N**2) w najgorszym przypadku. Jako element podziału wybiera się element: środkowy, pierwszy, ostatni, losowy, medianę, medianę z trzech (chodzi o zapobieganie niekorzystnym przypadkom). Element podziału trafia od razu na swoje miejsce. Algorytm jest niestabilny.

# Wersja wg Kernighana i Ritchiego.

def quicksort(L, left, right):
    if left >= right:
        return
    swap(L, left, (left + right) // 2)   # element podziału
    pivot = left                      # przesuń do L[left]
    for i in range(left + 1, right + 1):   # podział
        if L[i] < L[left]:
            pivot += 1
            swap(L, pivot, i)
    swap(L, left, pivot)     # odtwórz element podziału
    quicksort(L, left, pivot - 1)
    quicksort(L, pivot + 1, right)

# Wersja wg Cormena.

def quicksort(L, left, right):
    """Sortowanie szybkie wg Cormena str. 169."""
    if left >= right:
        return
    pivot = partition(L, left, right)
    # pivot jest na swoim miejscu.
    quicksort(L, left, pivot - 1)
    quicksort(L, pivot + 1, right)

def partition(L, left, right):
    """Zwraca indeks elementu rozdzielającego."""
    # Element rozdzielający to ostatni z prawej,
    # dlatego na końcu trzeba go przerzucić do środka.
    # Będzie on na docelowej pozycji ze względu na sortowanie.
    x = L[right]   # element rozdzielający
    i = left
    for j in range(left, right):
        if L[j] <= x:
            swap(L, i, j)
            i += 1
    swap(L, i, right)
    return i

Algorytm można przyspieszyć wywołując dla małych ciągów inną metodę sortowania, np. insertsort().

# Typowo m wynosi między 5 a 25.
if (right - left) <= m:
    insertsort(L, left, right)



Sortowanie przez scalanie (mergesort)
WPROWADZENIE

Algorytm sortowania przez scalanie wymaga dodatkowego obszaru pamięci proporcjonalnego do liczby N sortowanych elementów. Sortowanie przez scalanie jest stabilne. Metoda dobrze nadaje się do sortowania danych dostępnych sekwencyjnie (listy). Czas działania algorytmu nie zależy od sposobu uporządkowania danych wejściowych.

    Dziel (Divide): Podziel N-elementową sekwencję do posortowania na dwie sekwencje o długości N/2 każda.
    Zwyciężaj (Conquer): Posortuj dwie podsekwencje rekurencyjnie wykorzystując mergesort.
    Połącz (Combine): Złącz dwie posortowane sekwencje w jedną posortowaną sekwencję, która stanowi rozwiązanie. 

def mergesort(L, left, right):
    """Sortowanie przez scalanie."""
    if left < right:
        middle = (left + right) // 2   # wyznaczanie środka 
        mergesort(L, left, middle)
        mergesort(L, middle + 1, right)
        merge(L, left, middle, right)   # scalanie

def merge(L, left, middle, right):
    """Łączenie posortowanych sekwencji."""
    T = [None] * (right - left + 1)
    left1 = left
    right1 = middle
    left2 = middle + 1
    right2 = right
    i = 0
    while left1 <= right1 and left2 <= right2:
        if L[left1] <= L[left2]:   # mniejsze lub równe
            T[i] = L[left1]
            left1 += 1
        else:
            T[i] = L[left2]
            left2 += 1
        i += 1
    # Lewa lub prawa część może mieć elementy.
    while left1 <= right1:
        T[i] = L[left1]
        left1 += 1
        i += 1
    while left2 <= right2:
        T[i] = L[left2]
        left2 += 1
        i += 1
    # Skopiuj z tablicy tymczasowej do oryginalnej.
    for i in range(right - left +1):
        L[left + i] = T[i]

def merge(L, left, middle, right):
    """Łączenie posortowanych sekwencji z wartownikami."""
    n1 = middle - left + 1
    n2 = right - middle
    A = [None] * (n1 + 1)   # o jeden więcej
    B = [None] * (n2 + 1)   # o jeden więcej
    for i in range(n1):
        A[i] = L[left + i]
    for i in range(n2):
        B[i] = L[middle + 1 + i]
    A[n1] = float("inf")   # wartownik
    B[n2] = float("inf")   # wartownik
    i, j = 0, 0
    for k in range(left, right+1):
        if A[i] <= B[j]:
            L[k] = A[i]
            i += 1
        else:
            L[k] = B[j]
            j += 1

ZŁOŻONOŚĆ

Czas sortowania listy o długości N oznaczamy przez T(N), przy czym T(1) = c. Z definicji algorytmu dostajemy zależność rekurencyjną
T(N) = 2 * T(N/2) + c * N,
gdzie c * N to czas scalenia dwóch uporządkowanych ciągów w jeden ciąg N elementowy.

Z twierdzenia wynika, że czas T(N) jest rzędu O(N * log(N)). Liczba porównań w algorytmie sortowania przez scalanie jest rzędu O(N * log(N)).

|T(N)    c*N                   c*N
|       /   \                /     \
|   T(N/2)  T(N/2)      c*N/2       c*N/2
|                      /    \       /    \
|                  T(N/4) T(N/4) T(N/4) T(N/4)
|
|             c*N  ............................ c*N
|            /    \
|       c*N/2       c*N/2  .................... c*N
|      /    \       /    \
|  c*N/4  c*N/4  c*N/4  c*N/4  ................ c*N
|  /  \   /  \   /  \   /  \
|
|  | | | | | | | | | | | | | | | |
|  c c c c c c c c c c c c c c c c  ........... c*N
|
| Drzewo będzie miało log(N)+1 poziomów, a suma wyrazów
| z każdego poziomu wynosi c*N.

KOMENTARZE

Naturalne sortowanie przez scalanie potrafi wykorzystać naturalnie istniejące podciągi posortowane, przez co można zredukować liczbę przebiegów scalania [por. timsort]. Dane posortowane nie będą wymagały w ogóle scalania.

Algorytm mergesort daje się łatwo zrównoleglić z uwagi na zastosowanie techniki dziel i zwyciężaj [CLRS]. Zrównolegla się nie tylko rekurencyjny podział na listy, ale także etap scalania. Wtedy dla N procesorów czas sortowania jest O(log(N)). 


    
